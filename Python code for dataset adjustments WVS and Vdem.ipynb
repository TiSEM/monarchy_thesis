{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e793d373-434d-4de9-a7c9-f55ad35cb9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "##Part 1 Installl ibararies \n",
    "#Run the following line if any of the following libraries are not installed\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87e36ef5-a716-468a-b2ec-5c7976ac1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: loading necessary packages\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3c685e3-e09a-422c-b159-12b30990e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 100000 rows\n",
      "Processing chunk with 100000 rows\n",
      "Processing chunk with 100000 rows\n",
      "Processing chunk with 100000 rows\n",
      "Processing chunk with 43488 rows\n"
     ]
    }
   ],
   "source": [
    "#Part 3: Loading the data from WVS\n",
    "\n",
    "# Path to the large file\n",
    "file_path_WVS = r\"C:\\Users\\Lenovo\\Downloads\\F00011931-WVS_Time_Series_1981-2022_csv_v5_0\\WVS_Time_Series_1981-2022_csv_v5_0.csv\"\n",
    "\n",
    "# Define the chunk size \n",
    "chunk_size1 = 100000\n",
    "\n",
    "# Create an empty list to store chunks\n",
    "chunks1 = []\n",
    "\n",
    "# Read the file in chunks\n",
    "for chunk in pd.read_csv(file_path_WVS, chunksize=chunk_size1):\n",
    "    # Process each chunk \n",
    "    print(f\"Processing chunk with {len(chunk)} rows\")\n",
    "    chunks1.append(chunk)\n",
    "\n",
    "# Combine all chunks into a single DataFrame (optional)\n",
    "data_WVS = pd.concat(chunks1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a51bea62-f807-450b-b080-f48adb9ba4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['version', 'doi', 'S001', 'S002VS', 'S003', 'COUNTRY_ALPHA', 'COW_NUM',\n",
      "       'COW_ALPHA', 'S004', 'S006',\n",
      "       ...\n",
      "       'Y023A', 'Y023B', 'Y023C', 'Y024A', 'Y024B', 'Y024C', 'survself',\n",
      "       'tradrat5', 'TradAgg', 'SurvSAgg'],\n",
      "      dtype='object', length=1046)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 443488 entries, 0 to 443487\n",
      "Columns: 1046 entries, version to SurvSAgg\n",
      "dtypes: float64(42), int64(1000), object(4)\n",
      "memory usage: 3.5+ GB\n",
      "None\n",
      "              version                        doi  S001  S002VS  S003  \\\n",
      "0  5-0-0 (2024-04-30)  doi.org/10.14281/18241.25     2       3     8   \n",
      "1  5-0-0 (2024-04-30)  doi.org/10.14281/18241.25     2       3     8   \n",
      "2  5-0-0 (2024-04-30)  doi.org/10.14281/18241.25     2       3     8   \n",
      "3  5-0-0 (2024-04-30)  doi.org/10.14281/18241.25     2       3     8   \n",
      "4  5-0-0 (2024-04-30)  doi.org/10.14281/18241.25     2       3     8   \n",
      "\n",
      "  COUNTRY_ALPHA  COW_NUM COW_ALPHA  S004  S006  ...     Y023A     Y023B  \\\n",
      "0           ALB      339       ALB     1     1  ...  0.000000  0.444444   \n",
      "1           ALB      339       ALB     1     2  ...  0.111111  0.444444   \n",
      "2           ALB      339       ALB     1     3  ...  0.000000  0.444444   \n",
      "3           ALB      339       ALB     1     4  ...  0.000000  0.333333   \n",
      "4           ALB      339       ALB     1     5  ...  0.000000  0.333333   \n",
      "\n",
      "      Y023C  Y024A  Y024B  Y024C  survself  tradrat5   TradAgg  SurvSAgg  \n",
      "0  0.444444   0.33    0.0  0.165 -1.011276  0.160847  0.158964 -1.792410  \n",
      "1  0.444444   0.33    0.0  0.165 -0.688773  0.409283  0.558946 -1.208679  \n",
      "2  0.444444   0.33    0.5  0.415       NaN       NaN       NaN       NaN  \n",
      "3  0.333333   0.33    0.0  0.165 -1.319863  0.733956  1.081669 -2.350952  \n",
      "4  0.333333   0.00    0.5  0.250       NaN       NaN       NaN       NaN  \n",
      "\n",
      "[5 rows x 1046 columns]\n"
     ]
    }
   ],
   "source": [
    "#Part 5: Adjusting WVS dataset\n",
    "\n",
    "#Define variables to keep\n",
    "variables_to_keep_WVS = ['S020', 'A006', 'A008', 'A165', 'A168A', 'A170', 'A214', 'D001', 'E012', 'E046', 'E069_11', 'F034', 'F167', 'G006', 'G007_01', 'G007_18', 'G007_64', 'G255', 'X001', 'X003', 'Y011B', 'COUNTRY_ALPHA']\n",
    "\n",
    "#Select those columns from the data that match with the variables to keep\n",
    "data_WVS = data_WVS[variables_to_keep_WVS]\n",
    "\n",
    "#Rename variables for interpretability\n",
    "data_WVS = data_WVS.rename(columns = {'S020': 'year', 'A006': 'religion_importance', 'A008': 'happiness', 'A165': 'people_trustful', 'A168A': 'people_advantage', 'A170': 'life_satisfaction', 'A214': 'trusting', 'D001':'family_trust', 'E012': 'fight_for_country', 'E046': 'new_old_ideas', 'E069_11': 'confidence_government', 'F034': 'religious_person', 'F167': 'monarchy_islam', 'G006': 'proud_nationality', 'G007_01': 'trust_people_country', 'G007_18': 'trust_neigborhood', 'G007_64': 'trust_people_general', 'G255': 'feeling_close_town', 'X001': 'sex', 'X003': 'age', 'Y011B': 'national_pride', 'COUNTRY_ALPHA': 'country'})\n",
    "\n",
    "#Obtain the variable means by year and country\n",
    "data_means_WVS = data_WVS.groupby(['year', 'country']).mean()\n",
    "\n",
    "#Create new dataframe with only the country-year means\n",
    "data_individual_WVS = data_WVS\n",
    "data_means_df_WVS = pd.DataFrame(data_means_WVS)\n",
    "\n",
    "#Reset the index to make the country column available for manipulation\n",
    "data_means_df_reset_WVS = data_means_df_WVS.reset_index()\n",
    "\n",
    "#Change abbreviations to full country names\n",
    "#Create dictionary with mapping of the country abbreviations and full country names\n",
    "name_change_WVS = {'ALB': 'Albania', 'AND': 'Andorra', 'ARG': 'Argentina', 'ARM': 'Armenia', 'AUS': 'Australia', 'AZE': 'Azerbijan', 'BFA': 'Burkina Faso', 'BGD': 'Bangladesh', 'BGR': 'Bulgaria', \n",
    "               'BIH': 'Bosnia and Herzegovina','BLR': 'Belarus', 'BOL': 'Bolivia', 'BRA': 'Brazil', 'CAN': 'Canada', 'CHE': 'Switzerland', 'CHL': 'Chile', 'CHN': 'China', 'COL': 'Colombia', \n",
    "               'CYP': 'Cyprus', 'CZE': 'Czechia', 'DEU': 'Germany', 'DOM': 'Dominican Republic', 'DZA': 'Algeria', 'ECU': 'Ecuador', 'EGY': 'Egypt', 'ESP': 'Spain', 'EST': 'Estonia', 'ETH': \n",
    "               'Ethiopia', 'FIN': 'Finland', 'FRA': 'France', 'GBR': 'United Kingdom',  'GEO': 'Georgia', 'GHA': 'Ghana', 'GRC': 'Greece', 'GTM': 'Guatemala',  'HKG': 'Hong Kong',\n",
    "                 'HRV': 'Croatia', 'HTI': 'Haiti', 'HUN': 'Hungary', 'IDN': 'Indonesia', 'IND': 'India', 'IRN': 'Iran', 'IRQ': 'Iraq', 'ISR': 'Israel', 'ITA': 'Italy', 'JOR': 'Jordan', 'JPN': 'Japan', \n",
    "               'KAZ': 'Kazakhstan','KEN': 'Kenya', 'KGZ': 'Kyrgyzstan', 'KOR': 'South Korea', 'KWT': 'Kuwait', 'LBN': 'Lebanon', 'LBY': 'Libya', 'LTU': 'Lithuania', 'LVA': 'Latvia', 'MAC': 'Macau', \n",
    "               'MAR': 'Morocco', 'MDA': 'Moldova', 'MDV': 'Maldives', 'MEX': 'Mexico', 'MKD': 'North Macedonia', 'MLI': 'Mali', 'MMR': 'Myanmar', 'MNE': 'Montenegro', 'MNG': 'Mongolia', 'MYS': 'Malaysia', \n",
    "               'NGA': 'Nigeria', 'NIC': 'Nicaragua', 'NIR': 'North Ireland', 'NLD': 'Netherlands', 'NOR': 'Norway', 'NZL': 'New Zealand', 'PAK': 'Pakistan', 'PER': 'Peru', 'PHL': 'Philippines',\n",
    "               'POL': 'Poland', 'PRI': 'Puerto Rico', 'PSE': 'Palestine', 'QAT': 'Qatar', 'ROU': 'Romania', 'RUS': 'Russia', 'RWA': 'Rwanda', 'SAU': 'Saudi Arabia','SGP': 'Singapore', 'SLV': 'El Salvador', \n",
    "               'SRB': 'Serbia', 'SVK': 'Slovakia', 'SVN': 'Slovenia', 'SWE': 'Sweden', 'THA': 'Thailand', 'TJK': 'Tajikistan', 'TTO': 'Trinidad and Tobago', 'TUN': 'Tunesia', 'TUR': 'Turkiye', 'TWN': 'Taiwan',\n",
    "                 'TZA': 'Tanzania', 'UGA': 'Uganda', 'UKR': 'Ukraine', 'URY': 'Uruguay', 'USA': 'United States', 'UZB': 'Uzbekistan', 'VEN': 'Venezuela', 'VNM': 'Vietnam', 'YEM': 'Yemen', \n",
    "               'ZAF': 'South Africa', 'ZMB': 'Zambia','ZWE': 'Zimbabwe'}\n",
    "\n",
    "#Change country abbreviations to full country names\n",
    "data_means_df_reset_WVS['country'] = data_means_df_reset_WVS['country'].replace(name_change_WVS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efd163-d81d-4e16-912d-87194d4989ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 6: Download the adjusted WVS data\n",
    "df_final_WVS = data_means_df_reset_WVS\n",
    "\n",
    "# Save the DataFrame as a CSV\n",
    "df_final_WVS.to_csv('WVS_adjusted.csv', index=False)\n",
    "\n",
    "# Create a download link\n",
    "FileLink('WVS_adjusted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5cdd000-ae60-44d9-9155-d58280d0a31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 10000 rows\n",
      "Processing chunk with 7734 rows\n"
     ]
    }
   ],
   "source": [
    "#Part 7 Loading the Vdem dataset\n",
    "\n",
    "# Path to the large file\n",
    "file_path_vdem = r\"C:\\Users\\Lenovo\\Downloads\\V-Dem-CY-FullOthers-v14_csv_YyKfizl\\V-Dem-CY-Full+Others-v14.csv\"\n",
    "\n",
    "# Define the chunk size \n",
    "chunk_size2 = 10000\n",
    "\n",
    "# Create an empty list to store chunks\n",
    "chunks2 = []\n",
    "\n",
    "# Read the file in chunks\n",
    "for chunk in pd.read_csv(file_path_vdem, chunksize=chunk_size2, low_memory=False):\n",
    "    # Process each chunk \n",
    "    print(f\"Processing chunk with {len(chunk)} rows\")\n",
    "    chunks2.append(chunk)\n",
    "\n",
    "# Combine all chunks into a single DataFrame (optional)\n",
    "data_vdem = pd.concat(chunks2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d87ba87-0d22-4da6-956a-660d0330f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 8: Adjusting the Vdem dataset\n",
    "\n",
    "#Define variables to keep\n",
    "variables_to_keep_vdem = ['country_name', 'year', 'v2x_libdem', 'v2x_corr', 'v2cacamps', 'v2clacjust', 'e_wbgi_gee', 'e_peaveduc', 'v2peapssoc', 'v2smpolsoc', 'v2pesecsch', 'e_pelifeex']\n",
    "\n",
    "#Select those columns from the data that match with the variables to keep\n",
    "data_vdem = data_vdem[variables_to_keep_vdem]\n",
    "\n",
    "#Drop observation before 1980\n",
    "data_vdem = data_vdem[data_vdem['year'] >= 1980]\n",
    "\n",
    "#Rename variables for interpretability\n",
    "data_vdem_adjusted = data_vdem.rename(columns = {'country_name': 'country', 'v2x_libdem': 'liberal_democracy', 'v2x_corr': 'corruption', 'v2cacamps': 'society_camps',\n",
    "       'v2clacjust': 'socialclass_equality', 'e_wbgi_gee': 'government_effectiveness', 'e_peaveduc': 'education_rate', 'v2peapssoc': 'socialclass_access', 'v2smpolsoc': 'society_polarization',\n",
    "       'v2pesecsch': '2school_enrollment', 'e_pelifeex': 'life_expectancy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dccd323-4b25-41bf-852d-ae24d4c696c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='vdem_adjusted.csv' target='_blank'>vdem_adjusted.csv</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\Lenovo\\Downloads\\vdem_adjusted.csv"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 6: Download the adjusted Vdem data\n",
    "\n",
    "# Save the DataFrame as a CSV\n",
    "data_vdem_adjusted.to_csv('vdem_adjusted.csv', index=False)\n",
    "\n",
    "# Create a download link\n",
    "FileLink('vdem_adjusted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102978c-b953-4875-8aab-f2ed64e4f097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
